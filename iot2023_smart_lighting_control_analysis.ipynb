{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pytz\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attribute_from_line(attribute, line):\n",
    "    match = re.search(rf\"{attribute}: (\\d+)\", line)\n",
    "    return int(match.group(1)) if match else np.nan\n",
    "\n",
    "\n",
    "def timestamp_str_to_datetime(timestamp_str):\n",
    "    # Convert the timestamp string to a datetime object\n",
    "    return pytz.timezone('Europe/Paris').localize(datetime.datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "def timestamp_str_to_unix(timestamp_str):\n",
    "    # Convert the timestamp string to a datetime object\n",
    "    dt_obj = datetime.datetime.strptime(timestamp_str, \"%Y-%m-%d %H:%M:%S\").replace(tzinfo=pytz.timezone('Europe/Paris'))\n",
    "\n",
    "    # Convert the datetime object to a Unix timestamp\n",
    "    unix_timestamp = int(dt_obj.timestamp())\n",
    "\n",
    "    return unix_timestamp\n",
    "\n",
    "def unix_to_datetime(unix_timestamp):\n",
    "    return datetime.datetime.fromtimestamp(unix_timestamp, tz=pytz.timezone('Europe/Paris'))\n",
    "\n",
    "\n",
    "def separate_system_on_and_off_per_day(df, date):\n",
    "    # Define the time range for grouping (9am to 5pm)\n",
    "    start_time = datetime.time(9, 0)\n",
    "    end_time = datetime.time(17, 0)\n",
    "\n",
    "    # Initialize a dictionary to store the groups for each day\n",
    "    daily_groups = {}\n",
    "\n",
    "    # Iterate through the timestamps and group them accordingly\n",
    "    for dt in df.timestamp:  \n",
    "        date_key = dt.date()  # Use the date as the key for the dictionary\n",
    "\n",
    "        if start_time <= dt.time() <= end_time:\n",
    "\n",
    "            tens_number = (dt.minute // 10) + 1  # Calculate the interval\n",
    "\n",
    "            # Create a new list for the day if it doesn't exist in the dictionary\n",
    "            if date_key not in daily_groups:\n",
    "                daily_groups[date_key] = {\"system_on\": [], \"system_off\": []}\n",
    "\n",
    "            # Append the timestamp to the appropriate group based on the quarter\n",
    "            if tens_number in [1, 3, 5]:\n",
    "                daily_groups[date_key][\"system_on\"].append(dt)\n",
    "            elif tens_number in [2, 4, 6]:\n",
    "                daily_groups[date_key][\"system_off\"].append(dt)\n",
    "\n",
    "    single_day_system_on_timestamps = daily_groups[date][\"system_on\"]\n",
    "    single_day_system_off_timestamps = daily_groups[date][\"system_off\"]\n",
    "\n",
    "    single_day_system_on_df = df[df.timestamp.isin(single_day_system_on_timestamps)]\n",
    "    single_day_system_off_df = df[df.timestamp.isin(single_day_system_off_timestamps)]\n",
    "  \n",
    "    return single_day_system_on_df, single_day_system_off_df\n",
    " \n",
    "\n",
    "def read_txt_to_df(file_path):\n",
    "    #file_path: example \"long-monitorlog_2023-07-28.txt\"\n",
    "    file = open(file_path, \"r\")\n",
    "    lines = file.readlines()\n",
    "\n",
    "    data = []\n",
    "    buffer_lines = []\n",
    "    for line in lines:\n",
    "        if \"veml7700_lux\" in line:\n",
    "            buffer_lines.append(line)\n",
    "        elif \"as7262_temp\" in line:\n",
    "            buffer_lines.append(line)\n",
    "        elif \"veml6070_uv\" in line:\n",
    "            buffer_lines.append(line)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if len(buffer_lines) == 3:\n",
    "            first_timestamp = int(re.search(r\"\\['\\d+:\\d+:\\d+', '(\\d+)'\\]\", buffer_lines[0]).group(1))\n",
    "            last_timestamp = int(re.search(r\"\\['\\d+:\\d+:\\d+', '(\\d+)'\\]\", buffer_lines[2]).group(1))\n",
    "            if last_timestamp - first_timestamp > 2:\n",
    "                print(\"Something is wrong: \", first_timestamp, last_timestamp, last_timestamp - first_timestamp)\n",
    "\n",
    "            combined_line = \" \".join(buffer_lines)\n",
    "            timestamp = int(re.search(r\"\\['\\d+:\\d+:\\d+', '(\\d+)'\\]\", combined_line).group(1))\n",
    "            timestamp_wrong = extract_attribute_from_line(\"Timestamp\", combined_line)\n",
    "            node_id = extract_attribute_from_line(\"node_id\", combined_line)\n",
    "            veml7700_lux = extract_attribute_from_line(\"veml7700_lux\", combined_line)\n",
    "            sgp40_voc = extract_attribute_from_line(\"sgp40_voc\", combined_line)\n",
    "            shtc3_temperature = extract_attribute_from_line(\"shtc3_temperature\", combined_line)\n",
    "            shtc3_humidity = extract_attribute_from_line(\"shtc3_humidity\", combined_line)\n",
    "            as7262_temp = extract_attribute_from_line(\"as7262_temp\", combined_line)\n",
    "            as7262_violet = extract_attribute_from_line(\"as7262_violet\", combined_line)\n",
    "            as7262_blue = extract_attribute_from_line(\"as7262_blue\", combined_line)\n",
    "            as7262_green = extract_attribute_from_line(\"as7262_green\", combined_line)\n",
    "            as7262_yellow = extract_attribute_from_line(\"as7262_yellow\", combined_line)\n",
    "            as7262_orange = extract_attribute_from_line(\"as7262_orange\", combined_line)\n",
    "            as7262_red = extract_attribute_from_line(\"as7262_red\", combined_line)\n",
    "            veml6070_uv = extract_attribute_from_line(\"veml6070_uv\", combined_line)\n",
    "            si1145_lux = extract_attribute_from_line(\"si1145_lux\", combined_line)\n",
    "            si1145_infrared = extract_attribute_from_line(\"si1145_infrared\", combined_line)\n",
    "            si1145_uv = extract_attribute_from_line(\"si1145_uv\", combined_line)\n",
    "\n",
    "            # break\n",
    "            single_row = [timestamp,node_id, veml7700_lux, sgp40_voc, shtc3_temperature, shtc3_humidity,\n",
    "                    as7262_temp, as7262_violet, as7262_blue, as7262_green, as7262_yellow, as7262_orange, \n",
    "                    as7262_red, veml6070_uv, si1145_lux, si1145_infrared, si1145_uv]\n",
    "            \n",
    "            data.append(single_row)\n",
    "\n",
    "            buffer_lines.clear()\n",
    "\n",
    "    columns =   ['timestamp','node_id', 'veml7700_lux', 'sgp40_voc', 'shtc3_temperature', 'shtc3_humidity',\n",
    "                'as7262_temp', 'as7262_violet', 'as7262_blue', 'as7262_green', 'as7262_yellow', 'as7262_orange', \n",
    "                'as7262_red', 'veml6070_uv', 'si1145_lux', 'si1145_infrared', 'si1145_uv']\n",
    "    df =  pd.DataFrame(data, columns = columns)\n",
    "    return df\n",
    "\n",
    "def assign_intervals_to_column(df, target_column, start_time, end_time):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    df: a dataframe which should have a column timestamp of type datetime.\n",
    "    target_column: \n",
    "    \"\"\"\n",
    "    paris_tz = pytz.timezone('Europe/Paris')\n",
    "\n",
    "    # Define the time range for the plot (from 9 am to 5 pm)\n",
    "    start_datetime = timestamp_str_to_datetime(start_time)#\"e.g. ,2023-07-30 09:00:00\"\n",
    "    end_datetime = timestamp_str_to_datetime(end_time)#e.g.,(\"2023-07-30 17:00:00\")\n",
    "\n",
    "    target_column_df = df[['timestamp', target_column]].copy()\n",
    "    \n",
    "    # Group data into 10-minute intervals\n",
    "    target_column_df['interval'] = pd.cut(target_column_df['timestamp'], pd.date_range(start_datetime, end_datetime, freq='10T'))\n",
    "\n",
    "    # Convert interval labels to desired format\n",
    "    target_column_df['interval'] = target_column_df['interval'].apply(lambda x: f\"{x.mid.strftime('%H:%M')}\")\n",
    "\n",
    "    return target_column_df\n",
    "\n",
    "    \n",
    "def clean_sensor_data(df, switch_setting = True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert Unix timestamps to datetime objects\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: unix_to_datetime(x))\n",
    "\n",
    "    if switch_setting:\n",
    "        # remove the data in the first minute of each interval\n",
    "        df = df[df['timestamp'].dt.minute % 10 != 0]\n",
    "\n",
    "    # remove unreasonable lux values and cct values\n",
    "    print(f'Exclude {df[df.veml7700_lux > 3000].shape[0]} rows because of > 3000 lx.')\n",
    "    cleaned_df = df[df.veml7700_lux <= 3000]\n",
    "\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "def add_cct_column(df):\n",
    "    \n",
    "    data = df.copy()\n",
    "\n",
    "    V = data.as7262_violet\n",
    "    G = data.as7262_green\n",
    "    R = data.as7262_red\n",
    "\n",
    "    X = -0.14282 * R + 1.54924 * G + -0.95641 * V\n",
    "    Y = -0.32466 * R + 1.57837 * G + -0.73191 * V\n",
    "    Z = -0.68202 * R + 0.77073 * G + 0.56332 * V\n",
    "\n",
    "    #Step 2: calculate the chromaticity coordinates\n",
    "    x = X/(X + Y + Z)\n",
    "    y = Y/(X + Y + Z)\n",
    "\n",
    "    #Step 3: McCamyâ€™s formula (third version)\n",
    "    #https://onlinelibrary.wiley.com/doi/epdf/10.1002/col.5080170211\n",
    "    n = (x - 0.3320) / (0.1858 - y)\n",
    "    cct = 449 * n**3 + 3525 * n**2 + 6823.3 * n + 5520.33\n",
    "\n",
    "    data.loc[:,'cct'] = cct\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def barplot(system_on_data, system_off_data, date_str,  target_column, lower_hline = 500, higher_hline = 1000):\n",
    "    #date_str: example: 2023-07-31\n",
    "    grouped_system_on_data = assign_intervals_to_column(system_on_data, target_column, f\"{date_str} 09:00:00\", f\"{date_str} 17:00:00\")\n",
    "    grouped_system_off_data = assign_intervals_to_column(system_off_data, target_column, f\"{date_str} 09:00:00\", f\"{date_str} 17:00:00\")\n",
    "    \n",
    "    # Create the bar plot with error bars using seaborn\n",
    "    barplot_fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x='interval', y = target_column, data=grouped_system_on_data, ax=ax,color = '#404040', label = \"Smart Lighting Control System Switched On\")\n",
    "    sns.barplot(x='interval', y = target_column, data=grouped_system_off_data, ax=ax, color = '#A0A0A0', label = \"No Lamp Switched On\")\n",
    "\n",
    "\n",
    "    y_value_label = \"Illuminance (in lux)\"\n",
    "    plt.ylim(0,1500)\n",
    "    if target_column == 'cct':\n",
    "        y_value_label = \"CCT (in Kelvin)\"\n",
    "        plt.ylim(0,8000)\n",
    "    # Set plot labels and title\n",
    "    ax.set(xlabel='Time of the day', ylabel=f'Average {y_value_label}') \n",
    "    # title=f'{y_value_label} from 9am to 5pm on day {date_str}')\n",
    "\n",
    "    # Plot horizontal lines at y=500 and y=1000\n",
    "    ax.axhline(y=lower_hline, color='black', linestyle='dashed')\n",
    "    ax.axhline(y=higher_hline, color='black', linestyle='dashed')\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    # Set the x-ticks to display one point every hour\n",
    "    hourly_tick_labels = ['09:05', '10:05', '11:05', '12:05', '13:05', '14:05', '15:05', '16:05' ]\n",
    "    \n",
    "    plt.xticks([i for i in range(0, 48, 6)], hourly_tick_labels)\n",
    "\n",
    "    return barplot_fig, grouped_system_on_data, grouped_system_off_data\n",
    "\n",
    "def report_temp_humidity(df, start_time, end_time):\n",
    "\n",
    "    paris_tz = pytz.timezone('Europe/Paris')\n",
    "\n",
    "    # Define the time range for the plot (from 9 am to 5 pm)\n",
    "    start_datetime = timestamp_str_to_datetime(start_time)#\"e.g. ,2023-07-30 09:00:00\"\n",
    "    end_datetime = timestamp_str_to_datetime(end_time)#e.g.,(\"2023-07-30 17:00:00\")\n",
    "\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df[(df.timestamp >= start_datetime) & (df.timestamp < end_datetime)]\n",
    "    temp_mean = df.shtc3_temperature.mean()\n",
    "    temp_std = df.shtc3_temperature.std()\n",
    "\n",
    "    humidity_mean = df.shtc3_humidity.mean()\n",
    "    humidity_std = df.shtc3_humidity.std()\n",
    "\n",
    "    return temp_mean, temp_std, humidity_mean, humidity_std\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files and separate data when system was on and off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_txt_to_df(\"data/monitorlog_2023-08-15.txt\")\n",
    "data = add_cct_column(data)\n",
    "cleaned_sensor_data = clean_sensor_data(data)\n",
    "report_temp_humidity(cleaned_sensor_data, \"2023-08-15 09:00:00\", \"2023-08-15 17:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_on_data_0815, system_off_data_0815 = separate_system_on_and_off_per_day(cleaned_sensor_data, datetime.date(2023, 8, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_off_data_0815.cct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_off_data_0815.cct.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot lineplot for illuminance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_fig, grouped_system_on_data, grouped_system_off_data = barplot(system_on_data_0815, system_off_data_0815, \"2023-08-15\", \"veml7700_lux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare illuminance and CCT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(df, column):\n",
    "    \"\"\"\n",
    "    if n<= 50:\n",
    "        shapiro test\n",
    "    else:\n",
    "        D'Agostino's K^2 test\n",
    "\n",
    "    Parameters:\n",
    "    df: a dataframe.\n",
    "    column: the column that whose normality needs to be checked\n",
    "\n",
    "    Returns:\n",
    "    num_points: the number of data points\n",
    "    is_normality: a boolean value indicating whether the data is normally distributed\n",
    "    \"\"\"\n",
    "    num_points = df[~df[column].isna()].shape[0] \n",
    "    if num_points <= 50:\n",
    "       normality_test = stats.shapiro(df[column])\n",
    "    else:\n",
    "        normality_test = stats.normaltest(df[column])\n",
    "    if normality_test.pvalue <= 0.05:\n",
    "        return num_points, True\n",
    "    else:\n",
    "        return num_points, False\n",
    "    \n",
    "\n",
    "\n",
    "def get_mean_std(df, column):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    df: a dataframe.\n",
    "    column: the column that whose normality needs to be checked\n",
    "\n",
    "    Returns:\n",
    "    mean: the mean of the column\n",
    "    std: the standard deviation of the column\n",
    "    \"\"\"\n",
    "    data = df[column]\n",
    "    return data.mean(), data.std()\n",
    "\n",
    "def get_median_iqr(df, column):\n",
    "    # remove nan numbers first\n",
    "    data = df[~df[column].isna()][column]\n",
    "    median = data.median()\n",
    "    q1 = np.percentile(data, 25, interpolation='midpoint')\n",
    "    q3 = np.percentile(data, 75, interpolation='midpoint')\n",
    "    iqr = q3 - q1\n",
    "    return median, iqr\n",
    "\n",
    "\n",
    "def get_column_stats(df, column):\n",
    "\n",
    "    n, is_normal = check_normality(df, column)\n",
    "    if is_normal:\n",
    "        mean, std = get_mean_std(df, column)\n",
    "        return n, is_normal, mean, std\n",
    "    else:\n",
    "        median, iqr = get_median_iqr(df, column)\n",
    "        return n, is_normal, median, iqr\n",
    "    \n",
    "\n",
    "def welchs_t(group1, group2):\n",
    "    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    return t_stat, p_value\n",
    "\n",
    "def comparison_table(system_on_data, system_off_data, target_column):\n",
    "    results = []\n",
    "    results.append(get_column_stats(system_on_data, target_column))\n",
    "    results.append(get_column_stats(system_off_data, target_column))\n",
    "   \n",
    "    results.append(welchs_t(system_on_data[target_column], system_off_data[target_column]))\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_distance_from_range(x, lower, upper):\n",
    "    if x < lower:\n",
    "        return max(lower - x, 0)\n",
    "    elif x > upper:\n",
    "        return max(x - upper, 0)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def distance_comparison_table(system_on_data, system_off_data, target_column, target_lower, target_higher):\n",
    "    \n",
    "    system_on_data = system_on_data.copy()\n",
    "    system_off_data = system_off_data.copy()\n",
    "\n",
    "    #append distances to the dataframes\n",
    "    system_on_data['distance'] = system_on_data[target_column].apply(calculate_distance_from_range, args=(target_lower, target_higher))\n",
    "    system_off_data['distance'] = system_off_data[target_column].apply(calculate_distance_from_range, args=(target_lower, target_higher))\n",
    "    \n",
    "    results = []\n",
    "    results.append(get_column_stats(system_on_data, \"distance\"))\n",
    "    results.append(get_column_stats(system_off_data, \"distance\"))\n",
    "\n",
    "    results.append(welchs_t(system_on_data[\"distance\"], system_off_data[\"distance\"]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_comparison_table(system_on_data_0815, system_off_data_0815, \"veml7700_lux\", 500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table(system_on_data_0815, system_off_data_0815, \"veml7700_lux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic lighting figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dynamic_barplot(dynamic_data, date_str,  target_column, lower_hline = 500, higher_hline = 1000):\n",
    "    #date_str: example: 2023-07-31\n",
    "\n",
    "    grouped_dynamic_data = assign_intervals_to_column(dynamic_data, target_column, f\"{date_str} 09:00:00\", f\"{date_str} 17:00:00\")\n",
    "\n",
    "    # Create the bar plot with error bars using seaborn\n",
    "    barplot_fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x='interval', y = target_column, data=grouped_dynamic_data, ax=ax,color = '#808080', label = \"Smart Lighting Control System Switched On\")\n",
    "  \n",
    "    y_value_label = \"Illuminance (in lux)\"\n",
    "    # 9, 12, 13, 14, 16, 17, 19\n",
    "    hours = [0, 18, 24, 30, 42, 48]#[0, 12, 30, 36, 42, 54, 60, 72]\n",
    "    hours = [hour - 0.5 for hour in hours] #five minutes move from the center\n",
    "    print(hours)\n",
    "    target_values = [1000, 500, 500, 1000, 500, 500] #[500, 1000, 500, 500, 1000, 500, 500, 500] \n",
    "    variance = 50\n",
    "    plt.ylim(0,1500)\n",
    "    if target_column == 'cct':\n",
    "        y_value_label = \"CCT (in Kelvin)\"\n",
    "        target_values = [5000, 4000, 4000, 5000, 4000, 4000, 4000] #[5000, 4000, 4000, 5000, 4000, 4000]\n",
    "        variance = 300\n",
    "        plt.ylim(0,15000)\n",
    "    # Set plot labels and title\n",
    "    ax.set(xlabel='Time of the day', ylabel=f'Average {y_value_label}') \n",
    "    # title=f'{y_value_label} from 9am to 5pm on day {date_str}')\n",
    "\n",
    "    # Plot horizontal lines at y=500 and y=1000\n",
    "    ax.axhline(y=lower_hline, color='black', linestyle='dashed')\n",
    "    ax.axhline(y=higher_hline, color='black', linestyle='dashed')\n",
    "\n",
    "    ax.plot(hours, target_values, label='Target line', color='black')\n",
    "\n",
    "    # Create upper and lower shadow lines\n",
    "    upper_shadow = [val + variance for val in target_values]\n",
    "    lower_shadow = [val - variance for val in target_values]\n",
    "\n",
    "    # Fill the shadow regions\n",
    "    ax.fill_between(hours, lower_shadow, upper_shadow, color='#404040', alpha=0.2, label='Target area')\n",
    "\n",
    "\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    # Set the x-ticks to display one point every hour\n",
    "    hourly_tick_labels = ['09:05', '10:05', '11:05', '12:05', '13:05', '14:05', '15:05', '16:05']\n",
    "    \n",
    "    plt.xticks([i for i in range(0, 48, 6)], hourly_tick_labels)\n",
    "    \n",
    "\n",
    "    return barplot_fig, grouped_dynamic_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dynamic_data = read_txt_to_df(\"data/dynamic_monitorlog_2023-08-12.txt\")\n",
    "dynamic_data = add_cct_column(dynamic_data)\n",
    "\n",
    "cleaned_dynamic_data = clean_sensor_data(dynamic_data, switch_setting = False)\n",
    "report_temp_humidity(cleaned_dynamic_data, \"2023-08-13 09:00:00\", \"2023-08-13 17:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_lux_0812, df_lux_0812= dynamic_barplot(cleaned_dynamic_data, \"2023-08-13\", \"veml7700_lux\", lower_hline = 500, higher_hline = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
